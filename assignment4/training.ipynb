{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcfb5226",
   "metadata": {},
   "source": [
    "# Deep Learning for Computer Vision\n",
    "\n",
    "---\n",
    "\n",
    "**Goethe University Frankfurt am Main**\n",
    "\n",
    "Winter Semester 2022/23\n",
    "\n",
    "<br>\n",
    "\n",
    "## *Assignment 4 (Training)*\n",
    "\n",
    "---\n",
    "\n",
    "**Points:** 110<br>\n",
    "**Due:** 23.11.2022, 10 am<br>\n",
    "**Contact:** Matthias Fulde ([fulde@cs.uni-frankfurt.de](mailto:fulde@cs.uni-frankfurt.de))<br>\n",
    "\n",
    "---\n",
    "\n",
    "**Your Name:** Tilo-Lars Flasche\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870a32fd",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "---\n",
    "\n",
    "- [1 Nesterov Momentum](#1-Nesterov-Momentum-(10-Points))\n",
    "- [2 Batch Normalization](#2-Batch-Normalization-(20-Points))\n",
    "  - [2.1 Derivatives](#2.1-Derivatives-(15-Points))\n",
    "  - [2.2-Redundant Bias](#2.2-Redundant-Bias-(5-Points))\n",
    "- [3 Residual Networks](#3-Residual-Networks-(30-Points))\n",
    "  - [3.1 Block](#3.1-Block-(10-Points))\n",
    "  - [3.2 Network](#3.2-Network-(15-Points))\n",
    "  - [3.3 Capacity](#3.3-Capacity-(5-Points))\n",
    "- [4 Network Training](#4-Network-Training-(50-Points)\n",
    "  - [4.1 Solver](#4.1-Solver-(10-Points))\n",
    "  - [4.2 Training](#4.2-Training-(35-Points))\n",
    "  - [4.3 Analysis](#4.3-Analysis-(5-Points))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d054279f",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Setup\n",
    "\n",
    "---\n",
    "\n",
    "In this problem set we work with PyTorch, NumPy, and Matplotlib. See [this page](https://pytorch.org/get-started/locally/) for information on how to install PyTorch on your system.\n",
    "\n",
    "We set the Matplotlib backend to inline in order to display images directly in the notebook. In addition, we enable autoreloading so that saved changes in imported modules are applied without the need to manually reaload the modules every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61b13bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable autoreloading of imported modules.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98d1a32",
   "metadata": {},
   "source": [
    "In order to show the progress during training, we'll import the [tqdm](https://tqdm.github.io/) library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d778c7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tnrange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a860244",
   "metadata": {},
   "source": [
    "As you have observed in the last problem set, training a neural net without GPU support is terribly slow, even if we use the vector registers of the CPU. To accelerate training, we load the PyTorch library that allows us to perform the computations on the graphics card. You can check the GPU support of your environment with the statements below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "957f2255",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: [WinError 127] Die angegebene Prozedur wurde nicht gefunden\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# Check GPU support on your machine.\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1be9224",
   "metadata": {},
   "source": [
    "To avoid cluttering the notebook, we'll write our class and function definitions in external modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97a8b464",
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks import ResNet\n",
    "from solver import Solver\n",
    "from utils import show_training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8e45d7",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Definitions\n",
    "\n",
    "---\n",
    "\n",
    "For comparability, we want to be able to compute the `capacity` of a model, which is the total number of learnable parameters. This also includes biases and linear and affine parameters of normalization layers, but *not* hyperparameters like the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81861d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capacity(module):\n",
    "    \"\"\"\n",
    "    Computes the number of learnable parameters.\n",
    "\n",
    "    Parameters:\n",
    "        - module (nn.Module): Module with parameters.\n",
    "\n",
    "    Returns:\n",
    "        - num_param (int): Number of parameters.\n",
    "\n",
    "    \"\"\"\n",
    "    num_param = sum(p.numel() for p in module.parameters() if p.requires_grad)\n",
    "\n",
    "    return num_param"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03605d9",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Dataset\n",
    "\n",
    "---\n",
    "\n",
    "We'll use again the CIFAR-10 dataset for these assignment, but this time we'll load and preprocess the dataset using the Torchvision library.\n",
    "\n",
    "We can use the [Compose](https://pytorch.org/vision/stable/transforms.html#torchvision.transforms.Compose) function to chain multiple transformations that we wish to apply to our data. We first convert the images in the loaded training and test sets to PyTorch tensors using the [ToTensor](https://pytorch.org/vision/stable/transforms.html#torchvision.transforms.ToTensor) transform. The Torchvision datasets are PIL images in the range $[0,1]$ but we want the data to be centered, so we use the [Normalize](https://pytorch.org/vision/stable/transforms.html#torchvision.transforms.Normalize) transform to normalize the data to the $[-1,1]$ range.\n",
    "\n",
    "To tune the hyperparameters of our models, we want to split the training set into a smaller set for training and a set for validation. The [random_split](https://pytorch.org/docs/stable/data.html) function can be used to accomplish this, which takes a dataset and a list of sizes for the random subsets.\n",
    "\n",
    "Note that in the calls to `CIFAR10` below, you can safely keep the `download` parameter set to `True`. In case the dataset has been downloaded before to the given directory, it will be loaded from there and not downloaded from the internet again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "329b474d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Convert images to tensors and standardize data.\n",
    "transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((.5, .5, .5), (.5, .5, .5))\n",
    "])\n",
    "\n",
    "# Load and preprocess training set.\n",
    "data_train = torchvision.datasets.CIFAR10(\n",
    "    root='./datasets',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "# Split training set into sets for training and validation.\n",
    "data_train, data_val = torch.utils.data.random_split(data_train, [49000, 1000])\n",
    "\n",
    "# Load and preprocess test set.\n",
    "data_test = torchvision.datasets.CIFAR10(\n",
    "    root='./datasets',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44d5599",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Example\n",
    "\n",
    "Since we have not worked with PyTorch so far, let's fsee an example on how to create a model and train it on the dataset.\n",
    "\n",
    "For simple feed forward networks we can use the [Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html?highlight=sequential#torch.nn.Sequential) class of the PyTorch library to stack the different layers. For this example, we'll create the same model that we implemented in the previous problem set, so we'll use [Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d) for the convolution layers, [MaxPool2d](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d) for the pooling layers, [Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear) for the fully-connected layers and [Dropout](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout) for the dropout layer.\n",
    "\n",
    "We'll use again the ReLU activation function, which we can plug in using the [ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU) class. With [Flatten](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html#torch.nn.Flatten) we can transform the tensor output of the last convolutional layer into a vector representation that is the input to the first linear layer.\n",
    "\n",
    "In order to be able to utilize the GPU for training, we have to transfer the parameters and buffers of our model to the respective device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "320f7ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the same model as in the last assignment.\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=3, out_channels=6, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2),\n",
    "    nn.Conv2d(in_channels=6, out_channels=8, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(in_features=512, out_features=32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=32, out_features=10)\n",
    ")\n",
    "\n",
    "# Transfer model to selected device.\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fd1d73",
   "metadata": {},
   "source": [
    "In order to train the model, we need a loss function and an optimizer. We'll use again [CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss) and stochastic gradient descent with momentum. For the latter we call [SGD](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD) with the parameters we want to optimize and provide values for learning rate and momentum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c98abe98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create loss function and optimizer.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c88feac",
   "metadata": {},
   "source": [
    "To access the images in our datasets, we use the [DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) class from the data utils of the PyTorch library. Using this class we don't have to sample the minibatches manually. The result is an iterable that provides us with chunks of data where each entry is a tuple of images and corresponding labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3683109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of samples per batch.\n",
    "batch_size = 128\n",
    "\n",
    "# Create loader for training set.\n",
    "loader_train = torch.utils.data.DataLoader(\n",
    "    data_train,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "# Create loader for test set.\n",
    "loader_test = torch.utils.data.DataLoader(\n",
    "    data_test,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe75e12",
   "metadata": {},
   "source": [
    "Now let's train the model for a couple of epochs.\n",
    "\n",
    "After each iteration, we reset the gradients to zero, since this is not done automatically. We compute the forward pass through our network, the loss and the backward pass. To perform the update, we call the `step` method of our optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91c5c62a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01567363739013672,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 26,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 5,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeb6b0a8c4d242a78435826aa8673ae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Enable training mode.\n",
    "model.train()\n",
    "\n",
    "# Set number of training epochs.\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in (pbar := tnrange(num_epochs)):\n",
    "    for inputs, labels in loader_train:\n",
    "\n",
    "        # Transfer data to selected device.\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Compute the forward pass.\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and backward pass.\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Update model parameters and reset gradients.\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    # Show most recent loss every epoch.\n",
    "    pbar.set_description(f'Epoch: {epoch + 1}  Loss: {loss.item():.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fdc1f6",
   "metadata": {},
   "source": [
    "Let's check how good our model works on the test set.\n",
    "\n",
    "When doing this, we can tell PyTorch that we don't need gradients with the `no_grad` method to allow faster computation. Besides that, we must remember to transfer the data to the GPU again. You should expect to see $> 50 \\%$ accuracy on the test set with the given model and hyperparameter settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e067319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 57.27%\n"
     ]
    }
   ],
   "source": [
    "# Correct predictions and samples.\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Enable evaluation mode.\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in loader_test:\n",
    "\n",
    "        # Transfer data to selected device.\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Compute the forward pass.\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Get predicted labels.\n",
    "        prediction = torch.argmax(outputs.data, 1)\n",
    "\n",
    "        # Store results for the current batch.\n",
    "        total += labels.size(0)\n",
    "        correct += torch.sum(prediction == labels).item()\n",
    "\n",
    "# Show the result.\n",
    "print(f'Accuracy: {100*correct / total:5.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060ae18b",
   "metadata": {},
   "source": [
    "An alternative to using the `Sequential` class for creating a model, which provides more flexibility, is to subclass [Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module). Instances of this class are callable but can also maintain state like model parameters. Furthermore, [functional](https://pytorch.org/docs/stable/nn.functional.html) provides functions instead of classes that we can call directly in our model. Using this approach, we could define the same model we created above as follows:\n",
    "\n",
    "<br>\n",
    "\n",
    "```Python\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Define conv layers.\n",
    "        self.conv1 = nn.Conv2d(3, 6, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(6, 8, 3, padding=1)\n",
    "\n",
    "        # Define fully-connected layers.\n",
    "        self.fc1 = nn.Linear(512, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "        # Define pooling layers.\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Pass input through conv net.\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "\n",
    "        # Flatten all but batch dimension.\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        # Pass input through fully-connected net.\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "When training your network, you might also consider to use a [learning rate scheduler](https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate), since for training deep neural networks, it's almost always beneficial to decrease the learning rate as training goes on.\n",
    "\n",
    "The reason for why this makes sense is quite simple:<br>\n",
    "\n",
    "- If you choose a *too large* learning rate, you can make some fast initial progress, but you won't be able to reach a good local minimum, because you jump over the bottom point and bounce back and forth.\n",
    "- If you choose a *too small* learning rate on the other hand, you'll probably reach a minimum, but training will take very long, because you only take tiny steps in the right direction.\n",
    "\n",
    "So it's better to start with a rather large learning rate and decrease it on the way down towards the minimum.\n",
    "\n",
    "Regarding regularization, the PyTorch optimizers take a `weight_decay` argument, allowing to use L2 regularization for the parameters.\n",
    "\n",
    "To get more thorough explanations on how all this works, we highly recommend to explore the [tutorials](https://pytorch.org/tutorials/) section on the PyTorch website and have a look at the documentation pages for the respective components."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31909d9",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Exercises\n",
    "\n",
    "---\n",
    "\n",
    "### 1 Nesterov Momentum (10 Points)\n",
    "\n",
    "---\n",
    "\n",
    "The classicial stochastic gradient descent with momentum update rule is given by\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "    \\boldsymbol{\\theta}^{(t+1)} = \\boldsymbol{\\theta}^{(t)} - V^{(t+1)}\n",
    "    \\hspace{2em}\\text{with}\\hspace{2em}\n",
    "    V^{(t+1)} = \\mu V^{(t)} + \\eta\\nabla\\mathcal{L}(\\boldsymbol{\\theta}^{(t)}),\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "where $\\boldsymbol{\\theta}$ is a parameter, $\\mathcal{L}$ is the loss function, $\\eta$ the learning rate, $V$ the velocity, and $\\mu$ the momentum.\n",
    "\n",
    "In Nesterov's accelerated gradient method, this update rule becomes\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "    \\boldsymbol{\\theta}^{(t+1)} = \\boldsymbol{\\theta}^{(t)} - V^{(t+1)}\n",
    "    \\hspace{2em}\\text{with}\\hspace{2em}\n",
    "    V^{(t+1)} = \\mu V^{(t)} + \\eta\\nabla\\mathcal{L}(\\boldsymbol{\\theta}^{(t)} - \\mu V^{(t)}),\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "that is, we make a partial update in the direction of the accumulated gradient, before we evaluate the loss function and compute the gradient for the final update of the parameter.\n",
    "\n",
    "Give an intuitive example for a situation in which Nesterov's method will perform a better update step than the classical momentum method. Be as precise as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d08a817",
   "metadata": {},
   "source": [
    "##### Answer\n",
    "\n",
    "*Write your answer here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2f4ec2",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 2 Batch Normalization (20 Points)\n",
    "\n",
    "---\n",
    "\n",
    "The batch normalizing transform for a vector $\\mathbf{x}^{(n)} \\in \\mathbb{R}^D$ of a minibatch $\\mathcal{B} \\subset \\mathbf{X}$ of $N$ samples is defined as\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "    \\mathbf{y}^{(n)} = \\gamma\\hat{\\mathbf{x}}^{(n)} + \\beta\n",
    "$$\n",
    "\n",
    "with\n",
    "\n",
    "$$\n",
    "    \\hat{\\mathbf{x}}^{(n)}\n",
    "    =\n",
    "    \\frac{\\mathbf{x}^{(n)}-\\mu_\\mathcal{B}}{\\sqrt{\\sigma_\\mathcal{B}^2+\\epsilon}}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "where the mean and variance are computed componentwise as\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "    \\mu_\\mathcal{B}\n",
    "    =\n",
    "    \\frac{1}{N} \\sum_{n=1}^N \\mathbf{x}^{(n)}\n",
    "    \\hspace{2em}\\text{and}\\hspace{2em}\n",
    "    \\sigma_\\mathcal{B}^2\n",
    "    =\n",
    "    \\frac{1}{N} \\sum_{n=1}^N (\\mathbf{x}^{(n)} - \\mu_\\mathcal{B})^2.\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "### 2.1 Derivatives (15 Points)\n",
    "\n",
    "---\n",
    "\n",
    "We assume that we know the partial derivatives of the loss $\\mathcal{L}$ with respect to the outputs $\\mathbf{y}^{(n)}$ of a batch norm layer. Compute the partial derivatives with respect to the variance $\\sigma_\\mathcal{B}^2$, the mean $\\mu_\\mathcal{B}$, and the layer inputs $\\mathbf{x}^{(n)}$, using the chain rule.\n",
    "\n",
    "You can directly use\n",
    "\n",
    "$$\n",
    "    \\frac{\\partial\\mathcal{L}}{\\partial\\hat{\\mathbf{x}}^{(n)}}\n",
    "    =\n",
    "    \\frac{\\partial\\mathcal{L}}{\\partial\\mathbf{y}^{(n)}}\\gamma.\n",
    "$$\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297cd2c3",
   "metadata": {},
   "source": [
    "##### Solution\n",
    "\n",
    "*Write your solution here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96042b6f",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 2.2 Redundant Bias (5 Points)\n",
    "\n",
    "---\n",
    "\n",
    "Ignoring the constant added for numerical stability, we can write the normalization transform as\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "    y = \\gamma\\left(\\frac{x - \\mu}{\\sigma}\\right) + \\beta,\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "where $x$ is the input, $y$ is the output, $\\mu$ and $\\sigma$ are mean and standard deviation, respectively, $\\gamma$ are the linear parameters, and $\\beta$ the affine parameters of the transformation. The difference between batch, layer, and instance normalizations is how the statistcs $\\mu$ and $\\sigma$ are computed.\n",
    "\n",
    "During inference, we use estimates of the mean and standard deviation based on moving averages obtained during training. Hence when testing the model, these terms are constant.\n",
    "\n",
    "Show that for $x = x^\\prime + b$, the bias $b$ is redundant, that is, we can learn $\\beta$ such that\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "    y = \\gamma\\left(\\frac{x^\\prime - \\mu}{\\sigma}\\right) + b.\n",
    "$$\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fd583a",
   "metadata": {},
   "source": [
    "##### Proof\n",
    "\n",
    "*Write your proof here.*\n",
    "\n",
    "<div style=\"text-align:right\">$\\square$</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0745051b",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 3 Residual Networks (30 Points)\n",
    "\n",
    "---\n",
    "\n",
    "In this exercise we want to implement a residual convolutional network, analogue to the ResNet architecture introduced in the lecture.\n",
    "\n",
    "<br>\n",
    "\n",
    "### 3.1 Block (10 Points)\n",
    "\n",
    "---\n",
    "\n",
    "In the `networks` module, complete the definition of the `ResidualBlock` class.\n",
    "\n",
    "The main branch of the residual block should consist of two conv layers, each followed by a spatial batch norm layer. For the first convolutional block, the normalization layer is followed by a ReLU activation. The number of filters in each of the two conv layers is equal to the parameter `out_channels` of the constructor. Both conv layers should use a kernel size of 3 and a padding of 1. The stride of the first conv layer is equal to the `stride` parameter of the constructor. The second conv layer uses a stride of 1. Neither of the two conv layers uses a bias.\n",
    "\n",
    "The skip connection should be the identity mapping if the shape of the output is equal to the shape of the input. If this is not the case, use a conv layer with kernel size 1 to adjust the shape. The conv layer should again be followed by a batch norm layer and have no bias.\n",
    "\n",
    "In the `forward` method of the class, pass the input through the two branches, add the result, and apply a final ReLU activation before storing the result in the `out` variable that is returned from the method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0480392a",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 3.2 Network (15 Points)\n",
    "\n",
    "---\n",
    "\n",
    "Now complete the definion of the `ResNet` class in the same file.\n",
    "\n",
    "The residual network should start with a single conv layer with 3 input channels, a kernel size of 3, and stride and padding being equal to 1. The first conv layer is followed by a batch norm layer and a ReLU activation.\n",
    "\n",
    "After this first convolutional block, the network should consist of a number of `ResidualBlock` instances, which are finally followed by an average pooling layer, whose result is flattened and fed into a `Linear` layer that maps to feature vectors of length 10. The last layer has no activation.\n",
    "\n",
    "The number of residual blocks, the number of channels, and the size of the respective feature maps, are up to you. However, the network that you define must not have more than $50.000$ parameters. This is a hard requirement!\n",
    "\n",
    "You can use the function `capacity` to verify that you're below this threshold. In order to get a good result when training the network later, you should try to come close to the allowed number of parameters, while respecting the given specifications.\n",
    "\n",
    "After training your model, you may come back to this exercise and change your architecture to see if you can get better results with a different setup, but make sure that you still meet the requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f4d2ff7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43850\n"
     ]
    }
   ],
   "source": [
    "# Create network instance.\n",
    "model = ResNet()\n",
    "\n",
    "# Check number of parameters.\n",
    "print(capacity(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04912d2f",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 3.3 Capacity (5 Points)\n",
    "\n",
    "---\n",
    "\n",
    "When implementing your model to solve the previous exercise, you had to keep your model capacity below a certain threshold.\n",
    "\n",
    "Calculate the number of learnable parameters in your model from hand. For each layer or block in your network give a formula to compute the number of parameters. In the end, the sum should match the number computed by the `capacity` function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d693d8",
   "metadata": {},
   "source": [
    "##### Answer\n",
    "\n",
    "*Write your answer here.*\n",
    "\n",
    "**2D Convolutional Layers**\n",
    "\n",
    "The number of parameters of a 2D convolutional layers can be calculated with the following formula:\n",
    "$$ \\text{kernel_size}^2 \\cdot (\\text{in_channels}+\\text{out_channels}) $$\n",
    "\n",
    "**2D Batch Normalization Layers**\n",
    "\n",
    "The number of parameters of a 2D batch normalization layer can be calculated with the formula:\n",
    "$$ 2 \\cdot \\text{num_features} $$\n",
    "where *num_features* is the number of inpput channels of the batch normalization layer. The batch normalization layer learns two vectors $\\beta$ and $\\gamma$, where each of these vectors has *num_features* components.\n",
    "\n",
    "**Activation functions**\n",
    "\n",
    "Activation functions do not have any learnable parameters. That holds for all activation functions like *ReLU*, *TanH* or *Sigmoid*\n",
    "\n",
    "**Linear Layers**\n",
    "\n",
    "Linear layers connect each input component with each output component. The number of parameters can be calculated as follows:\n",
    "$$ \\text{in_features} \\cdot \\text{out_features} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b9fe87",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 4 Network Training (50 Points)\n",
    "\n",
    "---\n",
    "\n",
    "Our goal in this exercise is to finally train a *good* classifier for the CIFAR-10 dataset.\n",
    "\n",
    "<br>\n",
    "\n",
    "### 4.1 Solver (10 Points)\n",
    "\n",
    "---\n",
    "\n",
    "Before we actually start with training, however, we want to write a reusable class that encapsulates the training logic. Such a class allows us to focus on the important aspects of the training and saves us work if we face this task again.\n",
    "\n",
    "In the `solver.py` module you find the definition of the `Solver` class.\n",
    "\n",
    "Read the code to see how it works. It creates a loss function, an optimizer, and optionally, a learning rate scheduler from the given names and arguments. Additional arguments like the `batch_size` are stored directly as attributes of the object. The class provides methods to `save` and `load` the training state, including the model parameters and the state of the optimizer and scheduler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853875fa",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 4.1.1 Test Method (3 Points)\n",
    "\n",
    "The first task is to complete the definition of the `test` method.\n",
    "\n",
    "The method takes a dataset and has an optional `num_samples` parameter. If its value is `None` the model is evaluated on the whole given dataset. If a value for this parameter is given, it should be used to randomly subsample the given dataset before testing.\n",
    "\n",
    "Create a `DataLoader` for the dataset using the stored batch size and `with torch.no_grad` evaluate the model. Compute the accuracy in percent and store it in the `accuracy` variable that is returned from the method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d82274",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 4.1.2 Train Method (7 Points)\n",
    "\n",
    "The second task is to complete the definition of the `train` method.\n",
    "\n",
    "In this method first create a `DataLoader` for the training set, using the stored batch size, then implement the train loop for the number of epochs given as an argument. In each epoch, increment the `self.epoch` counter. Store the *average* loss for the epoch in the `self.loss_history` list.\n",
    "\n",
    "Also once per epoch, call the `test` method with the training and validation datasets and the stored parameters for the number of samples to use for validation. Store the obtained accuracies in the `self.train_acc` and `self.val_acc` lists. If a scheduler is given, you should call the `step` method of the scheduler in every epoch.\n",
    "\n",
    "In addition, you should keep track of the best validation set accuracy. In every epoch, check if the accuracy is better than the best accuracy seen so far. If this is the case, store a copy of the model parameters. After the training has finished, load the parameters that produced the best accuracy back into the model.\n",
    "\n",
    "Use the `tnrange` function of tqdm to show a progress bar for the epochs and the current validation set accuracy, as in the example above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8590129",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 4.2 Training (35 Points)\n",
    "\n",
    "---\n",
    "\n",
    "Now use the `Solver` class and your implementation of `ResNet` to train a classifier for CIFAR-10.\n",
    "\n",
    "Experiment with different residual network architectures within the constraints formulated in the previous exercise, try different optimizers and, if you want, learning rate schedulers. Try to find good hyperparameter values for your model. The goal is to achieve at least $70\\%$ accuracy on the test set.\n",
    "\n",
    "The ten bonus points in this assignment are for training the model to $80\\%$ accuracy on the test set.\n",
    "\n",
    "After you finished training, save the best model in the `models` folder.\n",
    "\n",
    "<br>\n",
    "\n",
    "You can use the `show_training` function from the `utils.py` module to show the losses and accuracies recorded during training.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### 4.2.1 Solution\n",
    "\n",
    "Write your code in cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b76f5153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of residual blocks 1\n",
      "Start training ...\n",
      "[Epoch: 1] loss: 0.310\n",
      "[Epoch: 2] loss: 0.258\n",
      "[Epoch: 3] loss: 0.240\n",
      "[Epoch: 4] loss: 0.230\n",
      "[Epoch: 5] loss: 0.220\n",
      "[Epoch: 6] loss: 0.213\n",
      "[Epoch: 7] loss: 0.207\n",
      "[Epoch: 8] loss: 0.202\n",
      "[Epoch: 9] loss: 0.197\n",
      "[Epoch: 10] loss: 0.192\n",
      "[Epoch: 11] loss: 0.189\n",
      "[Epoch: 12] loss: 0.185\n",
      "[Epoch: 13] loss: 0.182\n",
      "[Epoch: 14] loss: 0.179\n",
      "[Epoch: 15] loss: 0.177\n",
      "[Epoch: 16] loss: 0.175\n",
      "[Epoch: 17] loss: 0.172\n",
      "[Epoch: 18] loss: 0.170\n",
      "[Epoch: 19] loss: 0.168\n",
      "[Epoch: 20] loss: 0.166\n",
      "[Epoch: 21] loss: 0.165\n",
      "[Epoch: 22] loss: 0.163\n",
      "[Epoch: 23] loss: 0.161\n",
      "[Epoch: 24] loss: 0.160\n",
      "[Epoch: 25] loss: 0.158\n",
      "[Epoch: 26] loss: 0.157\n",
      "[Epoch: 27] loss: 0.156\n",
      "[Epoch: 28] loss: 0.154\n",
      "[Epoch: 29] loss: 0.153\n",
      "[Epoch: 30] loss: 0.152\n",
      "[Epoch: 31] loss: 0.151\n",
      "[Epoch: 32] loss: 0.150\n",
      "[Epoch: 33] loss: 0.148\n",
      "[Epoch: 34] loss: 0.148\n",
      "[Epoch: 35] loss: 0.147\n",
      "[Epoch: 36] loss: 0.146\n",
      "[Epoch: 37] loss: 0.145\n",
      "[Epoch: 38] loss: 0.144\n",
      "[Epoch: 39] loss: 0.143\n",
      "[Epoch: 40] loss: 0.143\n",
      "[Epoch: 41] loss: 0.141\n",
      "[Epoch: 42] loss: 0.140\n",
      "[Epoch: 43] loss: 0.140\n",
      "[Epoch: 44] loss: 0.139\n",
      "[Epoch: 45] loss: 0.139\n",
      "[Epoch: 46] loss: 0.138\n",
      "[Epoch: 47] loss: 0.137\n",
      "[Epoch: 48] loss: 0.136\n",
      "[Epoch: 49] loss: 0.136\n",
      "[Epoch: 50] loss: 0.135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [], 'train_acc': [], 'val_acc': []}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate ResNet model\n",
    "model = ResNet()\n",
    "print(\"Number of residual blocks\", len(model.blocks))\n",
    "\n",
    "# Transfer model to selected device.\n",
    "model = model.to(device)\n",
    "\n",
    "# Instantiate Solver class\n",
    "solver = Solver(\n",
    "    model=model,\n",
    "    data={'train': data_train, 'val': data_val},\n",
    ")\n",
    "\n",
    "solver.train(num_epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1ea7de",
   "metadata": {},
   "source": [
    "###### <br>\n",
    "\n",
    "#### 4.2.2 Evaluation\n",
    "\n",
    "Compute and show the accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c025a812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 63.80%\n"
     ]
    }
   ],
   "source": [
    "accuracy = solver.test(data_test)\n",
    "\n",
    "print(f'Test accuracy: {accuracy:5.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47890c7",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 4.3 Analysis (5 Points)\n",
    "\n",
    "---\n",
    "\n",
    "Describe your approach and what you observed during training.\n",
    "\n",
    "What did you try and what were the results? Which methods or settings that you used worked and which did not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da50492",
   "metadata": {},
   "source": [
    "##### Answer\n",
    "\n",
    "*Write your answer here.*\n",
    "\n",
    "During training I found out than the first concolutional layers should have a high number of channels, which then decreases from layer to layer. I could not get good results with models that only had few channels for the first convolutional block. This could be explained by the fact that the first convolutional layers extract low level features from the images, and the more low level features a model can extract the more accurate zthe hig level features of later convolutional layers can be.\n",
    "\n",
    "I also found that I was not helpful to have a high number of channels at the end of the residual block. Each convolutional laer should decrease the number of channels which are then passed to the linear layer.\n",
    "\n",
    "Another finding when I experimented with the model architecture was that it was not helpful to stack multiple layers of residual blocks. The best models I could find during training wree modeld that had only a few number of convolutional layers. I think that modes with a high number of convolutional layers might be too complex for the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16390bc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
